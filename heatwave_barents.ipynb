{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcbc4c5-3f7f-4d84-b47e-1b261ff3d4e2",
   "metadata": {},
   "source": [
    "# Script for identifying marine heatwaves (MHWs) in the Barents Sea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b4dc6-f7c4-4fe1-ab6a-da5c8597143e",
   "metadata": {},
   "source": [
    "#### First, as we are using Python we need to import some libraries. **To quickly run a cell :\"Ctrl+Enter\"**. Try it with the cell bellow to import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c23bf-aee4-4dee-ac3f-75ee5317f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed83979-45d1-4b9a-a4e2-272ca46e70d9",
   "metadata": {},
   "source": [
    "#### To avoid warning messages run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee8671-9da5-4969-9cad-7597561b9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3387cf-4d81-4633-a98c-a5124e2d8d12",
   "metadata": {},
   "source": [
    "#### We also need a statistical tool to remove the trend. Import this by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cc865-133c-46eb-bb35-64017d308340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2239f2c2-df3a-482f-b778-15ed053409e2",
   "metadata": {},
   "source": [
    "#### Next import the **marineHeatWaves** module – conda must be run from /Python/MarineHeatWaves/directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f0430-b366-4dd1-a717-61391f365ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marineHeatWaves as mhw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31776f04-14c9-4ed9-bfeb-d38ad92115f7",
   "metadata": {},
   "source": [
    "#### Add in the paths where you have the data saved `dat_dir` and where you would like the figures to be saved `fig_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8aae7-3891-490e-9d8a-3fedb5dcec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dir = ''\n",
    "sav_dir = dat_dir\n",
    "fig_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8fb86-8c99-4056-9e54-854aec56a8d2",
   "metadata": {},
   "source": [
    "#### Choose which region you would like to focus on: \n",
    "> (uncomment the region you would like to look at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf40c2-ca57-46a7-829c-296c35ce332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#area = 'BIT'   # Bear Island Trough / BSO\n",
    "#area = 'PS'    # Pechora Sea\n",
    "#area = 'SB'    # Spitsbergen Bank\n",
    "#area = 'NB'    # North-eastern Barents Sea / BSX\n",
    "area = 'Full'   # Full Barents Sea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873769be-4dc2-4d78-b3bb-5f30830cb30f",
   "metadata": {},
   "source": [
    "#### Choose whether you would like to focus on surface or bottom MHWs:\n",
    "- `surfbot = 1`: surface  \n",
    "- `surfbot = 2`: bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcb22f-5d6f-4524-917c-dc1f656d0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfbot = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c77e1-0b22-431e-89cf-f8df63347d72",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2667362-92f1-4130-9e6e-8a07a7fbf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "if surfbot == 1:\n",
    "   ds = xr.open_dataset(dat_dir + 'TOPAZ_Tmp_Sur_' + area + '_1991_2022.nc')\n",
    "elif surfbot == 2:\n",
    "   ds = xr.open_dataset(dat_dir + 'TOPAZ_Tmp_Bot_' + area + '_1991_2022.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ca33a-3fec-4866-a8cc-9f6d52561b54",
   "metadata": {},
   "source": [
    "#### Average the data spatially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae5993-1611-4e48-b06f-ebd000de48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if surfbot == 1:\n",
    "   ds_avg = ds['thetao'].mean(dim=[\"longitude\",\"latitude\",\"depth\"],skipna=True).squeeze()\n",
    "elif surfbot == 2:\n",
    "   ds_avg = ds['bottomT'].mean(dim=[\"longitude\",\"latitude\"],skipna=True).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf33147-72cc-4887-9673-39efe2aca3dc",
   "metadata": {},
   "source": [
    "#### Put the time values into vector 'date'\n",
    "> This makes the dates appear in the format '2021-06-01'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504739b-a919-49eb-994a-e17a094120c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_date = ds['time'].data.astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509bf61c-5adc-4c8f-b142-bd4bc83679cb",
   "metadata": {},
   "source": [
    "#### Get your average temperature variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8c363-8b3d-4be3-9ff7-8525d6bd2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds_avg.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00984761-8174-49a6-9cdd-3afc39ce8ea8",
   "metadata": {},
   "source": [
    "#### Convert the date from np-datetime64 to datetime.date()\n",
    "> Dates become a list of Python datetime.date objects eg., 'datetime.date(2021, 6, 1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884b0eb-4009-4934-8b45-559127079f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_datetime = ocean_date.tolist()\n",
    "t = np.asarray([datetime.date.toordinal(tt) for tt in date_datetime])\n",
    "#t = np.arange(date(1991,1,1).toordinal(),date(2021,12,31).toordinal()+1)\n",
    "dates = [date.fromordinal(tt.astype(int)) for tt in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5840d5-78f1-4f89-bb48-adcd2f0e1e00",
   "metadata": {},
   "source": [
    "### Great! Now that you are set up you can use the MHW functions to detect MHWs and get statistics.\n",
    "- `mhw.detect()` outputs a list of MHW events over our time period and their characteristics, including **frequency** (number of events per year), **intensity** (maximum sea surface temperature anomaly, °C), and **duration** (days).  \n",
    "- It also outputs a climatology relative to which the MHW is defined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43baf427-7882-41da-a29f-c1a70d35b0d1",
   "metadata": {},
   "source": [
    "#### Choose which climatological reference period you would like to use:\n",
    "\n",
    "- `1` = 1991–2020  \n",
    "- `2` = 1996–2020  \n",
    "- `3` = 2001–2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74196e2-d1e0-4dd1-8b07-193e4b18f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clm = 1\n",
    "if clm == 1:\n",
    "   mhws, clim = mhw.detect(t, temp, [1991,2020])   # Using 1991-2020 for climatology\n",
    "   mhwc, climc = mhw.detect(t, temp, [1991,2020], coldSpells = True)   # Cold spells, Using 1991-2020 for climatology\n",
    "elif clm == 2:\n",
    "   mhws, clim = mhw.detect(t, temp, [1996,2020])   # Using 1996-2020 for climatology\n",
    "elif clm == 3:\n",
    "   mhws, clim = mhw.detect(t, temp, [2001,2020])   # Using 2001-2020 for climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53296b8-a959-4f45-8a02-38783321ac41",
   "metadata": {},
   "source": [
    "#### Calculate statistics using `blockAverage`\n",
    "> Use this function to compute averages for the selected time period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fc6dd-8199-49c2-ba51-e8dd6050c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhwBlock = mhw.blockAverage(t, mhws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738cabd1-7766-408e-a919-fad91956d131",
   "metadata": {},
   "source": [
    "#### Print results to a csv-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa64c1-305e-4cd3-bac7-cfada553ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_file = 0\n",
    "if print_file == 1:\n",
    "   if surfbot == 1:\n",
    "      f = open(dat_dir + 'MHW_statistics_' + area + '_surface.csv', 'w')\n",
    "   elif surfbot == 2:\n",
    "      f = open(dat_dir + 'MHW_statistics_' + area + '_bottom.csv', 'w')\n",
    "   writer = csv.writer(f)\n",
    "\n",
    "#writer.writeheader([\"daynumber\", \"clim season\", \"90 pct\", \"temp\"])\n",
    "   for i in range(0, len(t)):\n",
    "      writer.writerow([t[i], clim['seas'][i], clim['thresh'][i], temp[i]])\n",
    "\n",
    "   f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39bbf2b-5c24-4234-b81f-93b290e7c6c6",
   "metadata": {},
   "source": [
    "#### Print Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bb5d80-4340-46f4-ba35-17aaa8be5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "if surfbot == 1:\n",
    "   if clm == 1:\n",
    "      print(\"*** Surface statistics from TOPAZ for area \" + area + \" using climate period 1991-2020 ***\")\n",
    "   elif clm == 2:\n",
    "      print(\"*** Surface statistics from TOPAZ for area \" + area + \" using climate period 1996-2020 ***\")\n",
    "   elif clm == 3:\n",
    "      print(\"*** Surface statistics from TOPAZ for area \" + area + \" using climate period 2001-2020 ***\")\n",
    "elif surfbot == 2:\n",
    "   if clm == 1:\n",
    "      print(\"*** Bottom statistics from TOPAZ for area \" + area + \" using climate period 1991-2020 ***\")\n",
    "   elif clm == 2:\n",
    "      print(\"*** Bottom statistics from TOPAZ for area \" + area + \" using climate period 1996-2020 ***\")\n",
    "   elif clm == 3:\n",
    "      print(\"*** Bottom statistics from TOPAZ for area \" + area + \" using climate period 2001-2020 ***\")\n",
    "\n",
    "mean, trend, dtrend = mhw.meanTrend(mhwBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73712266-b064-414e-b0d2-39d501d85bd9",
   "metadata": {},
   "source": [
    "#### Print the characteristics of the events (frequency, intensity and duration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9a29e-c2b0-463a-b174-b630bbac0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat = 0\n",
    "if print_stat == 1:\n",
    " \n",
    "   print(\"There are on average \" + str(mean['count']) + \" MHWs in each year, \\n \\\n",
    "   with a linear trend of \" + str(10*trend['count']) + \" MHW events per decade \\n \\\n",
    "   This trend is statistically significant (p<0.05): \" \\\n",
    "   + str(np.abs(trend['count']) > dtrend['count']) + \"\\n\")\n",
    "\n",
    "   print(\"The average maximum intensity is \" + str(mean['intensity_max']) + \" deg C above climatology, \\n \\\n",
    "   with a linear trend of \" + str(10*trend['intensity_max']) + \" deg. C per decade \\n \\\n",
    "   This trend is statistically significant (p<0.05): \" \\\n",
    "   + str(np.abs(trend['intensity_max']) > dtrend['intensity_max']) + \"\\n\")\n",
    "\n",
    "   print(\"The average duration is \" + str(mean['duration']) + \" days per year, \\n \\\n",
    "   with a linear trend of \" + str(10*trend['duration']) + \" days per year per decade \\n \\\n",
    "   This trend is statistically significant (p<0.05): \" \\\n",
    "   + str(np.abs(trend['duration']) > dtrend['duration']) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfa0ac-df7d-44fa-9cb6-4df250f4a368",
   "metadata": {},
   "source": [
    "#### Check miscellaneous properties of MHWs for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7164b-833d-47f1-b98f-46bbd79b0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc = 0\n",
    "if misc == 1:\n",
    "   ev = np.argmax(mhws['intensity_cumulative'])\n",
    "\n",
    "   print('** Statistics on most intense event **')\n",
    "   print('Maximum intensity:', mhws['intensity_max'][ev], 'deg. C above the climatology')\n",
    "   print('Average intensity:', mhws['intensity_mean'][ev], 'deg. C above the climatology')\n",
    "   print('Maximum duration:', mhws['duration'][ev], 'days')\n",
    "   print('Start date:', mhws['date_start'][ev].strftime(\"%d %B %Y\"))\n",
    "   print('End date:', mhws['date_end'][ev].strftime(\"%d %B %Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6ad47-e1a9-4a95-b68b-7483ac5eab4b",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b7d66c-d986-48b6-aca7-312cb41c2b5b",
   "metadata": {},
   "source": [
    "#### Plot the event with the maximum cumulative intensity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362baab-2fb6-4b1e-b1a8-6066e6807ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "   fig, axs = plt.subplots(1, 1, figsize=(14,5))\n",
    "   plt.rc('font', size=14)\n",
    "   plt.rc('axes', labelsize=20)\n",
    "   plt.rc('xtick', labelsize=20)\n",
    "   plt.rc('ytick', labelsize=20)\n",
    "   plt.xticks(fontsize = 14)\n",
    "   plt.yticks(fontsize = 14)\n",
    "# Find indices for maximum cumulative event and shade all XX MHWs before and after in pink:\n",
    "#   for ev0 in np.arange(ev-29, ev+8, 1):\n",
    "# Spans used for Figure 3 (DO NOT CHANGE!):\n",
    "#   for ev0 in np.arange(ev-10, ev+10, 1):  # Full Surface\n",
    "#   for ev0 in np.arange(ev-5, ev+1, 1):    # Full Bottom\n",
    "#   for ev0 in np.arange(ev-12, ev+20, 1):  # BIT Surface\n",
    "#   for ev0 in np.arange(ev-6, ev+3, 1):    # BIT Bottom\n",
    "#   for ev0 in np.arange(ev-30, ev+2, 1):   # NB Surface\n",
    "   for ev0 in np.arange(ev-5, ev+1, 1):    # NB Bottom\n",
    "#   for ev0 in np.arange(ev-12, ev+6, 1):   # SB Surface\n",
    "#   for ev0 in np.arange(ev-10, ev+4, 1):   # SB Bottom\n",
    "#   for ev0 in np.arange(ev-12, ev+12, 1):  # PS Surface\n",
    "#   for ev0 in np.arange(ev-6, ev+3, 1):    # PS Bottom\n",
    "# Spans used for Supplementary Figure (DO NOT CHANGE!):\n",
    "#   for ev0 in np.arange(ev-18, ev+2, 1):  # Full Surface 1 (1991 - 2005)\n",
    "#   for ev0 in np.arange(ev-1, ev+1, 1):    # Full Bottom 1 (1991 - 2005)\n",
    "#   for ev0 in np.arange(ev-16, ev+12, 1):  # Full Surface 2 (2005 - 2022)\n",
    "#   for ev0 in np.arange(ev-4, ev+1, 1):    # Full Bottom 2 (2005 - 2022)\n",
    "# Spans used for 2012 Check:\n",
    "#   for ev0 in np.arange(ev-12, ev+2, 1):  # Full Surface (2012 - 2014)\n",
    "#   for ev0 in np.arange(ev-4, ev+1, 1):    # Full Bottom (2012 - 2014)\n",
    "#   for ev0 in np.arange(ev-16, ev+12, 1):  # BIT Surface (2012 - 2014)\n",
    "#   for ev0 in np.arange(ev-10, ev+1, 1):    # BIT Bottom (2012 - 2014)\n",
    "#   for ev0 in np.arange(ev-16, ev+12, 1):  # PS Surface (2012 - 2014)\n",
    "#   for ev0 in np.arange(ev-8, ev+1, 1):    # PS Bottom (2012 - 2014)\n",
    "#   for ev0 in np.arange(ev-18, ev+6, 1):  # NB Surface (2012 - 2014)\n",
    "#   for ev0 in np.arange(ev-6, ev+1, 1):    # NB Bottom (2012 - 2014)\n",
    "      t1 = np.where(t==mhws['time_start'][ev0])[0][0]\n",
    "      t2 = np.where(t==mhws['time_end'][ev0])[0][0]\n",
    "      plt.fill_between(dates[t1:t2+1], temp[t1:t2+1], clim['thresh'][t1:t2+1], color=(1,0.6,0.5))\n",
    "# Shade largest cumulative event in dark red:\n",
    "   t1 = np.where(t==mhws['time_start'][ev])[0][0]\n",
    "   t2 = np.where(t==mhws['time_end'][ev])[0][0]\n",
    "   plt.fill_between(dates[t1:t2+1], temp[t1:t2+1], clim['thresh'][t1:t2+1], color='r')\n",
    "# Plot SST, seasonal cycle, threshold, shade MHWs with main event in red\n",
    "   axs.plot(dates, temp, 'k-', linewidth=2)\n",
    "   axs.plot(dates, clim['thresh'], 'g-', linewidth=2)\n",
    "   axs.plot(dates, clim['seas'], 'b-', linewidth=2)\n",
    "   if surfbot == 1:\n",
    "      axs.set_xlim(16436, 17532)   # 1.1.2015 - 1.1.2018\n",
    "#      axs.set_xlim(15340, 16071)   # 1.1.2012 - 1.1.2014\n",
    "#      axs.set_xlim(7670, 19358)   # 1.1.1991 - 1.1.2023\n",
    "#      axs.set_xlim(7670, 12784)   # 1.1.1991 - 1.1.2005\n",
    "#      axs.set_xlim(12784, 19358)   # 1.1.2005 - 1.1.2023\n",
    "   elif surfbot == 2:\n",
    "      axs.set_xlim(16436, 17532)   # 1.1.2015 - 1.1.2018\n",
    "#      axs.set_xlim(15340, 16071)   # 1.1.2012 - 1.1.2014\n",
    "#      axs.set_xlim(7670, 19358)   # 1.1.1991 - 1.1.2023\n",
    "#      axs.set_xlim(7670, 12784)   # 1.1.1991 - 1.1.2005\n",
    "#      axs.set_xlim(12784, 19358)   # 1.1.2005 - 1.1.2023\n",
    "      axs.set_ylim(clim['seas'].min() - 1, clim['seas'].max() + mhws['intensity_max'][ev] + 0.5)\n",
    "   if surfbot == 1:\n",
    "      axs.set_ylabel(r'Surface temperature [$^\\circ$C]', size=14)\n",
    "   elif surfbot == 2:\n",
    "      axs.set_ylabel(r'Bottom temperature [$^\\circ$C]', size=14)\n",
    "#   axs.xaxis.set_major_locator(mdates.MonthLocator(bymonth=(1, 4, 7, 10)))\n",
    "   axs.xaxis.set_major_locator(mdates.MonthLocator(bymonth=(1, 7)))   # Used in Fig. 3 (DO NOT CHANGE!)\n",
    "#   axs.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "#   axs.xaxis.set_major_locator(mdates.YearLocator(base=5))\n",
    "#   axs.xaxis.set_minor_locator(mdates.YearLocator())\n",
    "#   axs.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
    "# Inserting panel labels:\n",
    "   if surfbot == 1:\n",
    "      if area == 'Full':\n",
    "         plt.text(.05,.9, 'a)', fontsize = 14, transform = axs.transAxes)\n",
    "#         plt.text(.05,.9, 'c)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'BIT':\n",
    "         plt.text(.05,.9, 'b)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'NB':\n",
    "         plt.text(.05,.9, 'c)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'SB':\n",
    "         plt.text(.05,.9, 'd)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'PS':\n",
    "         plt.text(.05,.9, 'e)', fontsize = 14, transform = axs.transAxes)\n",
    "   elif surfbot == 2:\n",
    "      if area == 'Full':\n",
    "         plt.text(.05,.9, 'f)', fontsize = 14, transform = axs.transAxes)\n",
    "#         plt.text(.05,.9, 'd)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'BIT':\n",
    "         plt.text(.05,.9, 'g)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'NB':\n",
    "         plt.text(.05,.9, 'h)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'SB':\n",
    "         plt.text(.05,.9, 'i)', fontsize = 14, transform = axs.transAxes)\n",
    "      elif area == 'PS':\n",
    "         plt.text(.05,.9, 'j)', fontsize = 14, transform = axs.transAxes)\n",
    "\n",
    "\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b93b0-c72c-4619-94b6-c629bea903b0",
   "metadata": {},
   "source": [
    "#### Plot an Ocean Monitoring Index (OMI) Figure:\n",
    "\n",
    "> NB an Ocean Monitoring Index plot is a time series visualization used to track and analyze MHWs relative to a defined climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5dc40a-9f21-4656-bb15-968a1b0fbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "omi_fig = 1\n",
    "if omi_fig == 1:\n",
    "   omi_index = (temp - clim['seas']) / (clim['thresh'] - clim['seas'])\n",
    "\n",
    "   fig, axs = plt.subplots(1, 1, figsize=(20,4))\n",
    "   plt.rc('font', size=14)\n",
    "   plt.rc('axes', labelsize=20)\n",
    "   plt.rc('xtick', labelsize=20)\n",
    "   plt.rc('ytick', labelsize=20)\n",
    "   plt.xticks(fontsize = 14)\n",
    "   plt.yticks(fontsize = 14)\n",
    "\n",
    "   ev = np.argmax(mhws['intensity_cumulative'])\n",
    "   if surfbot == 1:\n",
    "      for ev0 in np.arange(ev-20, ev+12, 1):\n",
    "         t1 = np.where(t==mhws['time_start'][ev0])[0][0]\n",
    "         t2 = np.where(t==mhws['time_end'][ev0])[0][0]\n",
    "         plt.fill_between(dates[t1:t2+1], omi_index[t1:t2+1], 1, color='r')\n",
    "   elif surfbot == 2:\n",
    "      for ev0 in np.arange(ev-4, ev+1, 1):\n",
    "         t1 = np.where(t==mhws['time_start'][ev0])[0][0]\n",
    "         t2 = np.where(t==mhws['time_end'][ev0])[0][0]\n",
    "         plt.fill_between(dates[t1:t2+1], omi_index[t1:t2+1], 1, color='r')\n",
    "\n",
    "   evc = np.argmax(mhwc['intensity_cumulative'])\n",
    "   if surfbot == 1:\n",
    "      for evc0 in np.arange(evc-26, evc+4, 1):\n",
    "         t1 = np.where(t==mhwc['time_start'][evc0])[0][0]\n",
    "         t2 = np.where(t==mhwc['time_end'][evc0])[0][0]\n",
    "         plt.fill_between(dates[t1:t2+1], omi_index[t1:t2+1], -1, color='b')\n",
    "#         plt.fill_between(dates[t1:t2+1], -1, omi_index[t1:t2+1], color='b')\n",
    "   elif surfbot == 2:\n",
    "      for evc0 in np.arange(evc-9, evc+2, 1):\n",
    "         t1 = np.where(t==mhwc['time_start'][evc0])[0][0]\n",
    "         t2 = np.where(t==mhwc['time_end'][evc0])[0][0]\n",
    "#         plt.fill_between(dates[t1:t2+1], omi_index[t1:t2+1], -1, color='b')\n",
    "         plt.fill_between(dates[t1:t2+1], -1, omi_index[t1:t2+1], color='b')\n",
    "   axs.plot(dates, omi_index, 'k-', linewidth=2)\n",
    "\n",
    "\n",
    "   axs.set_xlim(7670, 19358)   # 1.1.1991 - 1.1.2023\n",
    "   axs.set_ylim(- 2.5, 2.5)\n",
    "\n",
    "   if surfbot == 1:\n",
    "      axs.set_ylabel(r'Surface MHW index', size=14)\n",
    "   elif surfbot == 2:\n",
    "      axs.set_ylabel(r'Bottom MHW index', size=14)\n",
    "\n",
    "   axs.xaxis.set_major_locator(mdates.YearLocator(base=5))\n",
    "\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0ab07-bf35-4b02-8d21-f3f6b087252f",
   "metadata": {},
   "source": [
    "#### Plot a bar chart showing the duration of all events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da439db2-e7b2-4e28-87d8-f4920b57a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart = 0\n",
    "if barchart == 1:\n",
    "   ev = np.argmax(mhws['intensity_cumulative'])\n",
    "\n",
    "   plt.figure(figsize=(14,5))\n",
    "# Duration\n",
    "   plt.subplot(1,1,1)\n",
    "   evMax = np.argmax(mhws['duration'])\n",
    "   plt.bar(range(mhws['n_events']), mhws['duration'], width=0.6, color=(0.7,0.7,0.7))\n",
    "   plt.bar(evMax, mhws['duration'][evMax], width=0.6, color=(1,0.5,0.5))\n",
    "   plt.bar(ev, mhws['duration'][ev], width=0.6, edgecolor=(1,0.,0.), color='none')\n",
    "   plt.xlim(0, mhws['n_events'])\n",
    "   plt.ylabel('[days]')\n",
    "   plt.title('Duration')\n",
    "   plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ece973-e965-4b5e-b013-5c19d89b0bfa",
   "metadata": {},
   "source": [
    "#### Plot timeseries of the number of events (frequency), max intensity, and duration of all events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda58ee8-1373-4439-b540-ba13b15af883",
   "metadata": {},
   "outputs": [],
   "source": [
    "tseries = 0\n",
    "if tseries == 1:\n",
    "\n",
    "   plt.figure(figsize=(14,4))\n",
    "\n",
    "   plt.subplot(2,2,1)\n",
    "   plt.plot(mhwBlock['years_centre'], mhwBlock['count'], 'k-o')\n",
    "   plt.ylim(0,9)\n",
    "   plt.ylabel('[Count]')\n",
    "   plt.title('Number of MHWs by year')\n",
    "\n",
    "   plt.subplot(2,2,2)\n",
    "   plt.plot(mhwBlock['years_centre'], mhwBlock['duration'], 'k-o')\n",
    "   plt.ylim(0,400)\n",
    "   plt.ylabel(r'[Days]')\n",
    "   plt.title('MHW duration')\n",
    "\n",
    "   plt.subplot(2,2,3)\n",
    "   plt.plot(mhwBlock['years_centre'], mhwBlock['total_icum'], 'k-o')\n",
    "   plt.ylabel(r'[$^\\circ$C x days]')\n",
    "#   plt.title('Average MHW maximum intensity by year')\n",
    "\n",
    "   ev = np.argmax(mhws['intensity_cumulative'])\n",
    "   evMax = np.argmax(mhws['duration'])\n",
    "   plt.subplot(2,2,4)\n",
    "   plt.bar(range(mhws['n_events']), mhws['duration'], width=0.6, color=(0.7,0.7,0.7))\n",
    "   plt.bar(evMax, mhws['duration'][evMax], width=0.6, color=(1,0.5,0.5))\n",
    "   plt.bar(ev, mhws['duration'][ev], width=0.6, edgecolor=(1,0.,0.), color='none')\n",
    "   plt.xlim(0, mhws['n_events'])\n",
    "   plt.xlabel('[MHW #]')\n",
    "   plt.ylabel('[Days]')\n",
    "#   plt.title('Duration')\n",
    "\n",
    "\n",
    "   plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
